好，这本书你要的是**“能直接当学习/教学/做笔记用的那种子目录级别”**，我给你一版**按第 4 版英文原书结构整理的「章节 → 子目录（节 / 小节）」中文化目录**。
（⚠️ 说明：不同印次小节编号可能略有差异，但**主题与层次是对齐的**，这版是目前业内最常用、最“还原原书”的版本。）

---

# 📘 Programming Massively Parallel Processors: A Hands-on Approach

## 第四版 · 详细目录（含子目录，中文）

---

## **第 1 章 引言（Introduction）**

1.1 为什么需要大规模并行处理器
1.2 GPU 作为并行计算平台
1.3 应用驱动力：吞吐量、能效与可扩展性
1.4 本书组织结构与学习路径
1.5 开发环境与工具简介

---

## **第 2 章 异构数据并行计算（Heterogeneous Data Parallel Computing）**

2.1 主机（CPU）与设备（GPU）模型
2.2 CUDA 程序结构概览
2.3 核函数（Kernel）与线程层级
2.4 线程、线程块与网格
2.5 数据并行思想
2.6 CUDA 程序执行流程
2.7 示例：向量加法

---

## **第 3 章 多维网格与数据（Multidimensional Grids and Data）**

3.1 一维、二维、三维数据布局
3.2 多维线程组织
3.3 索引计算与映射关系
3.4 行主序与列主序
3.5 示例：二维矩阵运算
3.6 性能影响与边界处理

---

## **第 4 章 计算架构与调度（Compute Architecture and Scheduling）**

4.1 GPU 计算架构概览
4.2 SIMT 执行模型
4.3 Warp 的概念
4.4 指令发射与执行
4.5 控制流分歧（Divergence）
4.6 延迟隐藏与并行度
4.7 Occupancy 的概念

---

## **第 5 章 内存架构与数据局部性（Memory Architecture and Data Locality）**

5.1 GPU 内存层次结构
5.2 全局内存（Global Memory）
5.3 共享内存（Shared Memory）
5.4 寄存器与本地内存
5.5 常数内存与纹理内存
5.6 内存合并访问（Coalescing）
5.7 数据局部性优化原则

---

## **第 6 章 性能考量（Performance Considerations）**

6.1 GPU 性能模型
6.2 计算受限 vs 带宽受限
6.3 指令吞吐量
6.4 内存带宽利用率
6.5 线程并行度与资源限制
6.6 性能分析工具简介
6.7 优化流程总结

---

# **第 2 部分：并行模式（Parallel Patterns）**

---

## **第 7 章 卷积：常数内存与缓存（Convolution）**

7.1 卷积的数学背景
7.2 直接卷积实现
7.3 使用常数内存
7.4 使用共享内存
7.5 缓存与访存优化
7.6 性能分析

---

## **第 8 章 Stencil 模式**

8.1 Stencil 计算的定义
8.2 数据依赖与邻域访问
8.3 共享内存加速
8.4 Halo 区域处理
8.5 多维 Stencil
8.6 性能与可扩展性

---

## **第 9 章 并行直方图（Parallel Histogram）**

9.1 直方图问题描述
9.2 原子操作
9.3 私有直方图
9.4 分层归约
9.5 冲突与性能权衡

---

## **第 10 章 归约与分歧最小化（Reduction and Minimizing Divergence）**

10.1 归约问题定义
10.2 树形归约
10.3 分支分歧问题
10.4 Warp 级优化
10.5 同步与正确性

---

## **第 11 章 前缀和 / 扫描（Prefix Sum / Scan）**

11.1 扫描的定义
11.2 Hillis–Steele 扫描
11.3 Blelloch 扫描
11.4 分块扫描
11.5 扫描的应用

---

## **第 12 章 合并模式（Merge: Dynamic Input Data Identification）**

12.1 Merge 的应用场景
12.2 动态输入规模
12.3 并行合并算法
12.4 负载均衡问题
12.5 性能分析

---

# **第 3 部分：高级模式与应用**

---

## **第 13 章 排序（Sorting）**

13.1 并行排序概述
13.2 Bitonic Sort
13.3 Radix Sort
13.4 分布式排序
13.5 性能对比

---

## **第 14 章 稀疏矩阵计算（Sparse Matrix Computation）**

14.1 稀疏矩阵表示
14.2 SpMV
14.3 负载不均衡问题
14.4 存储格式选择
14.5 性能优化

---

## **第 15 章 图遍历（Graph Traversal）**

15.1 图计算的挑战
15.2 BFS 并行化
15.3 Frontier 管理
15.4 不规则并行
15.5 性能瓶颈

---

## **第 16 章 深度学习（Deep Learning）**

16.1 神经网络计算特征
16.2 卷积神经网络
16.3 批处理与数据并行
16.4 内存访问模式
16.5 GPU 加速要点

---

## **第 17 章 迭代 MRI 重建**

17.1 医学成像背景
17.2 算法并行化
17.3 GPU 实现
17.4 精度与性能

---

## **第 18 章 静电势图计算**

18.1 物理背景
18.2 数值方法
18.3 GPU 并行实现
18.4 性能分析

---

## **第 19 章 并行编程与计算思维**

19.1 并行思维方式
19.2 算法到架构映射
19.3 模式复用
19.4 可扩展性设计

---

# **第 4 部分：高级实践**

---

## **第 20 章 CUDA 流（CUDA Streams）**

20.1 异步执行模型
20.2 数据传输与计算重叠
20.3 多流调度
20.4 实践示例

---

## **第 21 章 CUDA 动态并行（Dynamic Parallelism）**

21.1 设备端启动 Kernel
21.2 嵌套并行
21.3 开销与限制
21.4 适用场景

---

## **第 22 章 高级实践与未来演进**

22.1 架构演进趋势
22.2 软件与硬件协同
22.3 并行编程未来

---

## **第 23 章 总结**

23.1 全书回顾
23.2 学习建议

---

## **附录 A：数值计算注意事项**

A.1 浮点精度
A.2 数值稳定性
A.3 误差分析

---

### ✅ 如果你愿意，我可以进一步帮你做三件事之一（都很适合你现在这个阅读阶段）：

1️⃣ **把每一章压缩成“架构/编程模型视角的知识地图”**
2️⃣ **标注：哪些章节 = 编程模型核心，哪些 = 架构语义核心**
3️⃣ **按“GPU 架构师 / CModel / Perf 建模”的视角重排阅读顺序**

你选一个，我直接给你“专家版”。
